{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter notebook\n",
    "Copy (fork) and edit as many copies of this notebook as you require "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-06T15:56:36.745832Z",
     "iopub.status.busy": "2025-10-06T15:56:36.745119Z",
     "iopub.status.idle": "2025-10-06T15:56:38.744392Z",
     "shell.execute_reply": "2025-10-06T15:56:38.743657Z",
     "shell.execute_reply.started": "2025-10-06T15:56:36.745764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option(\"display.max_colwidth\", 72)\n",
    "\n",
    "seed = 42\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "# graphics\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 6.8)\n",
    "#plt.style.use('fivethirtyeight')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1)\n",
    "#sns.set_style(\"whitegrid\")\n",
    "\n",
    "import plotly.io as pio\n",
    "# for use in JupyterLab 4\n",
    "pio.renderers.default = 'iframe'\n",
    "# for use in Google Colab\n",
    "#pio.renderers.default = 'colab'\n",
    "import plotly as py\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T15:56:38.746407Z",
     "iopub.status.busy": "2025-10-06T15:56:38.745959Z",
     "iopub.status.idle": "2025-10-06T15:56:38.841396Z",
     "shell.execute_reply": "2025-10-06T15:56:38.840545Z",
     "shell.execute_reply.started": "2025-10-06T15:56:38.746378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ATTEND</th>\n",
       "      <th>BFACIL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CIG_0</th>\n",
       "      <th>DLMP_MM</th>\n",
       "      <th>DMAR</th>\n",
       "      <th>DOB_MM</th>\n",
       "      <th>DOB_TT</th>\n",
       "      <th>DOB_WK</th>\n",
       "      <th>FAGECOMB</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ILLB_R</th>\n",
       "      <th>ILOP_R</th>\n",
       "      <th>ILP_R</th>\n",
       "      <th>LD_INDL</th>\n",
       "      <th>MAGER</th>\n",
       "      <th>MBSTATE_REC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>M_Ht_In</th>\n",
       "      <th>NO_INFEC</th>\n",
       "      <th>NO_MMORB</th>\n",
       "      <th>NO_RISKS</th>\n",
       "      <th>PAY</th>\n",
       "      <th>PAY_REC</th>\n",
       "      <th>PRECARE</th>\n",
       "      <th>PREVIS</th>\n",
       "      <th>PRIORDEAD</th>\n",
       "      <th>PRIORLIVE</th>\n",
       "      <th>PRIORTERM</th>\n",
       "      <th>PWgt_R</th>\n",
       "      <th>RDMETH_REC</th>\n",
       "      <th>RESTATUS</th>\n",
       "      <th>RF_CESAR</th>\n",
       "      <th>RF_CESARN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WTGAIN</th>\n",
       "      <th>DBWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>3572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>712.0</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>Y</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>3315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>853.0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>888</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2054.0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>888</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>N</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "      <td>3005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>944.0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>3714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>6995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>6996</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>888</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>215.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>29</td>\n",
       "      <td>4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>6997</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>44.6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>N</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>6998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>888</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>6999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>888</td>\n",
       "      <td>39</td>\n",
       "      <td>N</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>3720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ATTEND  BFACIL   BMI  CIG_0  DLMP_MM DMAR  DOB_MM  DOB_TT  DOB_WK  \\\n",
       "0        0       1       1  21.3      0        7    1       5  1319.0       3   \n",
       "1        1       1       1  27.1      0       12    2       9   712.0       3   \n",
       "2        2       1       1  27.8      0        4    1      12   853.0       5   \n",
       "3        3       1       1  22.3      0       12    1       9  2054.0       2   \n",
       "4        4       1       1  22.7      0        2    1      11   944.0       3   \n",
       "...    ...     ...     ...   ...    ...      ...  ...     ...     ...     ...   \n",
       "6995  6995       1       1  20.2      0       11    1       8  1251.0       5   \n",
       "6996  6996       1       1  36.9      0        8    1       5  1757.0       4   \n",
       "6997  6997       3       1  44.6      0        9            6  1746.0       7   \n",
       "6998  6998       1       1  24.4      0        1    1      10     NaN       3   \n",
       "6999  6999       1       1  20.1      0        9    1       7   250.0       2   \n",
       "\n",
       "      FAGECOMB  FEDUC  ILLB_R  ILOP_R  ILP_R LD_INDL  MAGER  MBSTATE_REC  \\\n",
       "0           28      6     888     888    888       N     25            1   \n",
       "1           99      9      40     999    999       Y     26            1   \n",
       "2           25      4      29     888     29       N     25            1   \n",
       "3           38      6     888      22     22       N     38            1   \n",
       "4           29      4     999     999    999       N     30            1   \n",
       "...        ...    ...     ...     ...    ...     ...    ...          ...   \n",
       "6995        30      6      33      44     33       N     28            1   \n",
       "6996        37      5     888      36     36       N     31            1   \n",
       "6997        20      4     888     888    888       N     18            1   \n",
       "6998        33      6      15     888     15       N     32            1   \n",
       "6999        40      6      39     888     39       N     34            1   \n",
       "\n",
       "      MEDUC  M_Ht_In  NO_INFEC  NO_MMORB  NO_RISKS  PAY  PAY_REC  PRECARE  \\\n",
       "0         6       68         1         1         1    2        2        2   \n",
       "1         3       67         1         1         0    1        1        2   \n",
       "2         4       63         1         1         0    2        2        4   \n",
       "3         6       63         1         1         1    2        2        2   \n",
       "4         4       64         1         1         1    2        2        2   \n",
       "...     ...      ...       ...       ...       ...  ...      ...      ...   \n",
       "6995      6       66         1         1         1    2        2        2   \n",
       "6996      6       64         1         1         1    2        2        2   \n",
       "6997      3       64         1         1         1    2        2        2   \n",
       "6998      6       70         1         1         0    2        2        2   \n",
       "6999      8       68         1         1         1    2        2        3   \n",
       "\n",
       "      PREVIS  PRIORDEAD  PRIORLIVE  PRIORTERM  PWgt_R  RDMETH_REC  RESTATUS  \\\n",
       "0         13          0          0          0   140.0           1         2   \n",
       "1         13          0          2          3   173.0           1         1   \n",
       "2          8          0          2          0   157.0           3         1   \n",
       "3         13          0          0          1   126.0           1         1   \n",
       "4         12          0          2          1     NaN           1         2   \n",
       "...      ...        ...        ...        ...     ...         ...       ...   \n",
       "6995       9          0          1          1   125.0           1         2   \n",
       "6996      15          0          0          1   215.0           3         2   \n",
       "6997       9          0          0          0   260.0           1         1   \n",
       "6998      17          0          1          0   170.0           4         3   \n",
       "6999       9          0          1          0   132.0           1         1   \n",
       "\n",
       "     RF_CESAR  RF_CESARN SEX  WTGAIN  DBWT  \n",
       "0           N          0   F      37  3572  \n",
       "1           N          0   F      35  3315  \n",
       "2           N          0   M      41  1910  \n",
       "3           N          0   F      31  3005  \n",
       "4           N          0   F      18  3714  \n",
       "...       ...        ...  ..     ...   ...  \n",
       "6995        N          0   M      20  3374  \n",
       "6996        N          0   F      29  4195  \n",
       "6997        N          0   F       0  2900  \n",
       "6998        Y          1   F      45  3810  \n",
       "6999        N          0   F      28  3720  \n",
       "\n",
       "[7000 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the test data that you are asked to make predictions for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T15:57:05.885591Z",
     "iopub.status.busy": "2025-10-06T15:57:05.884831Z",
     "iopub.status.idle": "2025-10-06T15:57:05.924461Z",
     "shell.execute_reply": "2025-10-06T15:57:05.923725Z",
     "shell.execute_reply.started": "2025-10-06T15:57:05.88556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ATTEND</th>\n",
       "      <th>BFACIL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CIG_0</th>\n",
       "      <th>DLMP_MM</th>\n",
       "      <th>DMAR</th>\n",
       "      <th>DOB_MM</th>\n",
       "      <th>DOB_TT</th>\n",
       "      <th>DOB_WK</th>\n",
       "      <th>FAGECOMB</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>ILLB_R</th>\n",
       "      <th>ILOP_R</th>\n",
       "      <th>ILP_R</th>\n",
       "      <th>LD_INDL</th>\n",
       "      <th>MAGER</th>\n",
       "      <th>MBSTATE_REC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>M_Ht_In</th>\n",
       "      <th>NO_INFEC</th>\n",
       "      <th>NO_MMORB</th>\n",
       "      <th>NO_RISKS</th>\n",
       "      <th>PAY</th>\n",
       "      <th>PAY_REC</th>\n",
       "      <th>PRECARE</th>\n",
       "      <th>PREVIS</th>\n",
       "      <th>PRIORDEAD</th>\n",
       "      <th>PRIORLIVE</th>\n",
       "      <th>PRIORTERM</th>\n",
       "      <th>PWgt_R</th>\n",
       "      <th>RDMETH_REC</th>\n",
       "      <th>RESTATUS</th>\n",
       "      <th>RF_CESAR</th>\n",
       "      <th>RF_CESARN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WTGAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>412.0</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>888</td>\n",
       "      <td>29</td>\n",
       "      <td>Y</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>N</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>N</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>888</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>N</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>237.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>8995</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>888</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8996</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>888</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>Y</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>8997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>888</td>\n",
       "      <td>54</td>\n",
       "      <td>N</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>8998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>636.0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>888</td>\n",
       "      <td>74</td>\n",
       "      <td>N</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>8999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>N</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ATTEND  BFACIL   BMI  CIG_0  DLMP_MM DMAR  DOB_MM  DOB_TT  DOB_WK  \\\n",
       "0     7000       1       1  35.7      0       12    2       9   412.0       3   \n",
       "1     7001       1       1  24.2      0       11            8  1007.0       7   \n",
       "2     7002       1       1  20.2      0        5    2       2  1328.0       5   \n",
       "3     7003       1       1  23.0      0        8            5  2012.0       2   \n",
       "4     7004       1       1  37.1      0        3    2      12     NaN       2   \n",
       "...    ...     ...     ...   ...    ...      ...  ...     ...     ...     ...   \n",
       "1995  8995       2       1  20.4      0       11    1       8  1653.0       3   \n",
       "1996  8996       1       1  26.2      0        7    1       4  1021.0       6   \n",
       "1997  8997       1       1  35.9      0        9    1       6  1014.0       1   \n",
       "1998  8998       1       1  19.0      0       12    2       9   636.0       2   \n",
       "1999  8999       1       1  37.9      0        3    1      12  1125.0       6   \n",
       "\n",
       "      FAGECOMB  FEDUC  ILLB_R  ILOP_R  ILP_R LD_INDL  MAGER  MBSTATE_REC  \\\n",
       "0           38      4      29     888     29       Y     34            1   \n",
       "1           24      3     888     888    888       N     22            1   \n",
       "2           31      5     888     888    888       N     26            2   \n",
       "3           22      4     888     888    888       N     19            1   \n",
       "4           33      4     888     999    999       N     33            1   \n",
       "...        ...    ...     ...     ...    ...     ...    ...          ...   \n",
       "1995        29      7      16     888     16       N     32            1   \n",
       "1996        29      4     888     999    999       Y     27            1   \n",
       "1997        56      6      54     888     54       N     44            2   \n",
       "1998        29      6      74     888     74       N     28            1   \n",
       "1999        39      5     888     888    888       N     38            1   \n",
       "\n",
       "      MEDUC  M_Ht_In  NO_INFEC  NO_MMORB  NO_RISKS  PAY  PAY_REC  PRECARE  \\\n",
       "0         6       71         1         1         1    2        2        3   \n",
       "1         3       64         1         1         1    2        2        2   \n",
       "2         7       69         1         1         1    1        1        2   \n",
       "3         5       63         1         1         1    1        1        2   \n",
       "4         6       67         1         1         0    1        1        3   \n",
       "...     ...      ...       ...       ...       ...  ...      ...      ...   \n",
       "1995      4       67         1         1         1    2        2        3   \n",
       "1996      6       67         1         1         1    1        1        2   \n",
       "1997      6       68         1         1         0    2        2        2   \n",
       "1998      4       66         1         1         1    1        1        2   \n",
       "1999      5       69         1         1         1    2        2        2   \n",
       "\n",
       "      PREVIS  PRIORDEAD  PRIORLIVE  PRIORTERM  PWgt_R  RDMETH_REC  RESTATUS  \\\n",
       "0         11          0          1          0   256.0           1         2   \n",
       "1         11          0          0          0   141.0           1         1   \n",
       "2         16          0          0          0   137.0           3         2   \n",
       "3         10          0          0          0   130.0           1         1   \n",
       "4         13          0          0          2   237.0           3         1   \n",
       "...      ...        ...        ...        ...     ...         ...       ...   \n",
       "1995       7          0          4          0   130.0           1         3   \n",
       "1996      16          0          0          1   167.0           1         1   \n",
       "1997      11          0          1          0   236.0           4         1   \n",
       "1998      12          0          1          0   118.0           1         1   \n",
       "1999      16          0          0          0   257.0           3         2   \n",
       "\n",
       "     RF_CESAR  RF_CESARN SEX  WTGAIN  \n",
       "0           N          0   M      24  \n",
       "1           N          0   F      11  \n",
       "2           N          0   M      39  \n",
       "3           N          0   M      43  \n",
       "4           N          0   F      30  \n",
       "...       ...        ...  ..     ...  \n",
       "1995        N          0   F      18  \n",
       "1996        N          0   M      54  \n",
       "1997        Y          1   F      36  \n",
       "1998        N          0   F      41  \n",
       "1999        N          0   M      40  \n",
       "\n",
       "[2000 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structural cleaning before splitting\n",
    "def structural_cleaning(df, is_train=True):\n",
    "   df = df.copy()\n",
    "\n",
    "   # A. Filter target (only train)\n",
    "   if is_train and 'DBWT' in df.columns:\n",
    "       df = df[df['DBWT'] != 9999]\n",
    "\n",
    "   # B. Null codes\n",
    "   # Map 99, 999 ...\n",
    "   cols_99 = ['CIG_0', 'FAGECOMB', 'M_Ht_In', 'PREVIS']\n",
    "   for col in cols_99:\n",
    "       if col in df.columns:\n",
    "           df[col] = df[col].replace(99, np.nan)\n",
    "\n",
    "   cols_9 = ['FEDUC', 'MEDUC', 'BFACIL', 'ATTEND']\n",
    "   for col in cols_9:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace(9, np.nan)\n",
    "\n",
    "   if 'BMI' in df.columns:\n",
    "        df['BMI'] = df['BMI'].replace(99.9, np.nan)\n",
    "\n",
    "   # C. Structural nullity (888 -> 0)\n",
    "   cols_888 = ['ILLB_R', 'ILOP_R', 'ILP_R']\n",
    "   for col in cols_888:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace(888, 0)\n",
    "            df[col] = df[col].replace(999, np.nan)\n",
    "\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply structural cleaning to every df\n",
    "train_cleaned = structural_cleaning(train, is_train=True)\n",
    "test_cleaned = structural_cleaning(test, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting is based into 3 conjuntos\n",
    "1. Conjunto train: Is used so the model can learn parameters\n",
    "2. Conjunto validation: To select the best model and set hyperparameters to estimate errors of generalization during development.\n",
    "3. Conjunto test: Untouchable until the end. Gives a non-biassed estimation about how the model works irl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4200, 37) (aprox 60%)\n",
      "Val shape:   (1400, 37)   (aprox 20%)\n",
      "Test shape:  (1400, 37)  (aprox 20%)\n"
     ]
    }
   ],
   "source": [
    "# The target variable is 'Delivery Birth Weight' (DBWT)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate target variable to isolate the features (X)\n",
    "y = train_cleaned.pop('DBWT')\n",
    "X = train_cleaned\n",
    "\n",
    "# 80/20 ratio\n",
    "# Split the 20% of data for final testing\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# From the 80% training data, split again into training and validation sets (75/25 ratio)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape} (aprox 60%)\")\n",
    "print(f\"Val shape:   {X_val.shape}   (aprox 20%)\")\n",
    "print(f\"Test shape:  {X_test.shape}  (aprox 20%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a baseline signifies that every model turned in after this must best this result no matter what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline value: 3259.56\n",
      "Baseline RMSE on validation set: 581.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Define the prediction (mean of training target)\n",
    "baseline_pred = y_train.mean()\n",
    "print(f\"Baseline value: {baseline_pred:.2f}\")\n",
    "\n",
    "# Create a dummy prediction vector array for validation\n",
    "y_val_pred = np.full(len(y_val), baseline_pred)\n",
    "\n",
    "# Evaluate RMSE\n",
    "rmse = root_mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Baseline RMSE on validation set: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical imputation is the process of replacing missing data points in a dataset with plausible substituted values to maintaint data integrity. I did the splitting before filling in data to avoid data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting all the info from `UserGuide2018-508` shared in the Kaggle description I made a full data cleanup to try a standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that do not give predictive value\n",
    "drop_cols = ['id', 'DLMP_MM', 'DOB_TT'] # Exact dates that give noise\n",
    "\n",
    "# Numerical columns -> Candidates for median + scaling\n",
    "# Education has order: We try as a numerical\n",
    "num_cols = [\n",
    "    'BMI', 'CIG_0', 'FAGECOMB', 'ILLB_R', 'ILOP_R', 'ILP_R', 'MAGER',\n",
    "    'M_Ht_In', 'PRECARE', 'PREVIS', 'PRIORDEAD', 'PRIORLIVE', 'PRIORTERM',\n",
    "    'PWgt_R', 'RF_CESARN', 'WTGAIN', 'FEDUC', 'MEDUC'\n",
    "]\n",
    "\n",
    "# Categorical columns -> Candidates for mode + one-hot encoding\n",
    "# Text variables that do not have order\n",
    "cat_cols = [\n",
    "    'ATTEND', 'BFACIL', 'DMAR', 'DOB_MM', 'DOB_WK', 'LD_INDL',\n",
    "    'MBSTATE_REC', 'PAY', 'PAY_REC', 'RDMETH_REC', 'RESTATUS',\n",
    "    'RF_CESAR', 'SEX', 'NO_INFEC', 'NO_MMORB', 'NO_RISKS'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.14.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Lucia/Documents/GitHub/lusanmanso.kaggle.com/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Training stats learning\n",
    "def learn_imputation_stats(df):\n",
    "   stats = {}\n",
    "\n",
    "   # A. Numerical -> Median\n",
    "   for col in num_cols:\n",
    "      if col in df.columns:\n",
    "         stats[col] = df[col].median()\n",
    "\n",
    "   # B. Categorical -> Mode\n",
    "   for col in cat_cols:\n",
    "      if col in df.columns:\n",
    "         # dropna=True to avoid NaN in mode calculation\n",
    "         stats[col] = df[col].mode(dropna=True)[0]\n",
    "\n",
    "   return stats\n",
    "imputation_stats = learn_imputation_stats(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Really important for FAGECOMB -> Not having a father is predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def process_dataset(df, stats, scaler=None, is_train=False):\n",
    "   df = df.copy()\n",
    "\n",
    "   # A. Drop useless columns\n",
    "   df = df.drop([c for c in drop_cols if c in df.columns], axis=1)\n",
    "\n",
    "   # A.2 Feature Engineering\n",
    "   # 1. Peso total de la madre (Física)\n",
    "   if 'PWgt_R' in df.columns and 'WTGAIN' in df.columns:\n",
    "        df['Mother_Total_Weight'] = df['PWgt_R'] + df['WTGAIN']\n",
    "\n",
    "    # 2. Intensidad de tabaquismo (Interacción)\n",
    "   if 'CIG_0' in df.columns and 'MAGER' in df.columns:\n",
    "        df['Smoking_Intensity'] = df['CIG_0'] * df['MAGER']\n",
    "\n",
    "   # B. Missing indicators\n",
    "   cols_with_heavy_nan = ['FAGECOMB']\n",
    "   for col in cols_with_heavy_nan:\n",
    "      if col in df.columns:\n",
    "         # Creates a binary column: 1 if missing, 0 if not\n",
    "         df[f'{col}_is_missing'] = df[col].isna().astype(int)\n",
    "\n",
    "   # C. Imputation (fill in the blanks)\n",
    "   for col, value in stats.items():\n",
    "      if col in df.columns:\n",
    "         df[col] = df[col].fillna(value)\n",
    "\n",
    "   # Security check: if any NaN remains\n",
    "   df = df.fillna(0)\n",
    "\n",
    "   # D. One-hot encoding for categorical variables to dummy\n",
    "   # Change to string first to secure numerical codes are treated as categories\n",
    "   current_cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "   for col in current_cat_cols:\n",
    "      df[col] = df[col].astype(str)\n",
    "\n",
    "   df = pd.get_dummies(df, columns=current_cat_cols, drop_first=True) # drop_first avoids colineality\n",
    "\n",
    "   # E. Scaling (StandardScaler)\n",
    "   current_num_cols = [c for c in num_cols if c in df.columns]\n",
    "\n",
    "   if is_train:\n",
    "      scaler = StandardScaler()\n",
    "      df[current_num_cols] = scaler.fit_transform(df[current_num_cols])\n",
    "      return df, scaler\n",
    "   else:\n",
    "      # if Val/Test we use the scaler already trained (NOT RE-FIT)\n",
    "      if scaler is not None:\n",
    "         df[current_num_cols] = scaler.transform(df[current_num_cols])\n",
    "      return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline execution\n",
    "1. Process TRAIN & obtain adjusted scaler\n",
    "2. Process VALIDATION using stats & Train scaler\n",
    "3. Process TEST\n",
    "4. PROCESS TEST for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.14.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Lucia/Documents/GitHub/lusanmanso.kaggle.com/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "X_train_ready, scaler_fitted = process_dataset(X_train, imputation_stats, is_train=True)\n",
    "# 2\n",
    "X_val_ready = process_dataset(X_val, imputation_stats, scaler=scaler_fitted, is_train=False)\n",
    "# 3\n",
    "X_test_ready = process_dataset(X_test, imputation_stats, scaler=scaler_fitted, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding in the **D** step can generate distinct cols if in test missis some weird category. I force everyone to have EXACTLY the cols of X_train_ready\n",
    "expected_cols = X_train_ready.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train final shape: (4200, 76)\n",
      "Val final shape:   (1400, 76)\n",
      "Test final shape:  (1400, 76)\n"
     ]
    }
   ],
   "source": [
    "expected_cols = X_train_ready.columns\n",
    "\n",
    "def align_columns(df, target_cols):\n",
    "    # 1. Add missing cols (rellenas con 0)\n",
    "    missing_cols = set(target_cols) - set(df.columns)\n",
    "    for c in missing_cols:\n",
    "        df[c] = 0\n",
    "\n",
    "    # 2. Remove extra columns (that weren't in train)\n",
    "    # 3. Reordenar para que coincidan índice a índice\n",
    "    return df[target_cols]\n",
    "\n",
    "X_val_ready = align_columns(X_val_ready, expected_cols)\n",
    "X_test_ready = align_columns(X_test_ready, expected_cols)\n",
    "\n",
    "print(f\"Train final shape: {X_train_ready.shape}\")\n",
    "print(f\"Val final shape:   {X_val_ready.shape}\")\n",
    "print(f\"Test final shape:  {X_test_ready.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 550.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Entrenar\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predecir y evaluar\n",
    "preds = model.predict(X_val_ready)\n",
    "rmse = root_mean_squared_error(y_val, preds)\n",
    "\n",
    "print(f\"Linear Regression RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando los mejores hiperparámetros (paciencia)...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "\n",
      "Mejores parámetros encontrados: {'colsample_bytree': np.float64(0.6682096494749166), 'learning_rate': np.float64(0.023010318597055907), 'max_depth': 6, 'n_estimators': 1100, 'reg_alpha': np.float64(9.656320330745594), 'reg_lambda': np.float64(8.08397348116461), 'subsample': np.float64(0.7218455076693483)}\n",
      "Mejor Score (RMSE CV negativo): 545.60\n",
      "RMSE Final en Validación: 548.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# 1. Definir el espacio de búsqueda (Hyperparameter Space)\n",
    "# Estos son los \"knobs to twiddle\" mencionados en el Cap. 10\n",
    "param_dist = {\n",
    "    'n_estimators': randint(500, 3000),      # Cuántos árboles (Sección 10.4)\n",
    "    'learning_rate': uniform(0.01, 0.2),     # Velocidad de aprendizaje (Sección 10.5)\n",
    "    'max_depth': randint(3, 10),             # Profundidad de los árboles (Sección 10.3)\n",
    "    'subsample': uniform(0.6, 0.4),          # Evitar overfitting muestreando filas\n",
    "    'colsample_bytree': uniform(0.6, 0.4),   # Evitar overfitting muestreando columnas\n",
    "    'reg_alpha': uniform(0, 10),             # Regularización L1 (Sección 7.13.1)\n",
    "    'reg_lambda': uniform(0, 10)             # Regularización L2\n",
    "}\n",
    "\n",
    "# 2. Inicializar el regresor base\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "# 3. Configurar la Búsqueda Aleatoria\n",
    "# n_iter=50 significa que probará 50 combinaciones distintas\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='neg_root_mean_squared_error', # Kaggle usa RMSE\n",
    "    cv=3,                                  # Validación cruzada de 3 pliegues (Sección 5.2)\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. Entrenar (¡Esto buscará el mejor modelo posible!)\n",
    "print(\"Buscando los mejores hiperparámetros (paciencia)...\")\n",
    "random_search.fit(X_train_ready, y_train)\n",
    "\n",
    "# 5. Resultados\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"\\nMejores parámetros encontrados: {random_search.best_params_}\")\n",
    "print(f\"Mejor Score (RMSE CV negativo): {-random_search.best_score_:.2f}\")\n",
    "\n",
    "# 6. Validación final con tu Hold-out Set\n",
    "preds_val = best_model.predict(X_val_ready)\n",
    "rmse_val = root_mean_squared_error(y_val, preds_val)\n",
    "print(f\"RMSE Final en Validación: {rmse_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Kaggle shape: (2000, 76)\n"
     ]
    }
   ],
   "source": [
    "# Process the true kaggle test\n",
    "test_kaggle_ready = process_dataset(test_cleaned, imputation_stats, scaler=scaler_fitted, is_train=False)\n",
    "test_kaggle_ready = align_columns(test_kaggle_ready, expected_cols)\n",
    "\n",
    "print(f\"Test Kaggle shape: {test_kaggle_ready.shape}\") # Debería ser (2000, 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. ENTRENANDO XGBOOST ---\n",
      "XGBoost entrenado. Mejor iteración: 199\n",
      "\n",
      "--- 2. ENTRENANDO LIGHTGBM ---\n",
      "LightGBM entrenado. Mejor iteración: 203\n",
      "\n",
      "--- 3. EVALUACIÓN INTERNA (BLENDING) ---\n",
      "RMSE XGBoost:  539.15\n",
      "RMSE LightGBM: 537.34\n",
      "RMSE ENSAMBLE: 537.55 (¡Tu referencia real!)\n",
      "\n",
      "--- 4. GENERANDO SUBMISSION PARA KAGGLE ---\n"
     ]
    }
   ],
   "source": [
    "# [NUEVA CELDA PARA ENSEMBLING Y SUBMISSION - VERSIÓN XGBOOST MODERNO]\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- 1. ENTRENANDO XGBOOST ---\")\n",
    "\n",
    "# CORRECCIÓN: 'early_stopping_rounds' se define AHORA, al crear el modelo\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=1500,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror',\n",
    "    early_stopping_rounds=50  # <--- AQUI ES DONDE DEBE IR EN VERSIONES NUEVAS\n",
    ")\n",
    "\n",
    "# En el .fit() ya NO ponemos early_stopping_rounds, pero SÍ mantenemos el eval_set\n",
    "# para que el modelo tenga datos con los que medir cuándo parar.\n",
    "model_xgb.fit(\n",
    "    X_train_ready, y_train,\n",
    "    eval_set=[(X_val_ready, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"XGBoost entrenado. Mejor iteración: {model_xgb.best_iteration}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 2. ENTRENANDO LIGHTGBM ---\")\n",
    "model_lgb = lgb.LGBMRegressor(\n",
    "    n_estimators=1500,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=31,\n",
    "    feature_fraction=0.7,\n",
    "    bagging_fraction=0.7,\n",
    "    bagging_freq=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# LightGBM usa callbacks (esto sigue igual, es correcto)\n",
    "callbacks = [lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "\n",
    "model_lgb.fit(\n",
    "    X_train_ready, y_train,\n",
    "    eval_set=[(X_val_ready, y_val)],\n",
    "    eval_metric='rmse',\n",
    "    callbacks=callbacks\n",
    ")\n",
    "print(f\"LightGBM entrenado. Mejor iteración: {model_lgb.best_iteration_}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 3. EVALUACIÓN INTERNA (BLENDING) ---\")\n",
    "# Predecimos (automáticamente usan la mejor iteración gracias al early stopping)\n",
    "val_preds_xgb = model_xgb.predict(X_val_ready)\n",
    "val_preds_lgb = model_lgb.predict(X_val_ready)\n",
    "\n",
    "# PROMEDIO SIMPLE\n",
    "val_preds_ensemble = (val_preds_xgb * 0.5) + (val_preds_lgb * 0.5)\n",
    "\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_val, val_preds_xgb))\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_val, val_preds_lgb))\n",
    "rmse_ens = np.sqrt(mean_squared_error(y_val, val_preds_ensemble))\n",
    "\n",
    "print(f\"RMSE XGBoost:  {rmse_xgb:.2f}\")\n",
    "print(f\"RMSE LightGBM: {rmse_lgb:.2f}\")\n",
    "print(f\"RMSE ENSAMBLE: {rmse_ens:.2f} (¡Tu referencia real!)\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 4. GENERANDO SUBMISSION PARA KAGGLE ---\")\n",
    "# Predicciones finales sobre el test de competición\n",
    "kaggle_preds_xgb = model_xgb.predict(test_kaggle_ready)\n",
    "kaggle_preds_lgb = model_lgb.predict(test_kaggle_ready)\n",
    "\n",
    "# Blending final\n",
    "final_predictions = (kaggle_preds_xgb * 0.5) + (kaggle_preds_lgb * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StackingRegressor\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RidgeCV\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlgb\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- CONFIGURANDO EL APILAMIENTO (STACKING) ---\")\n",
    "\n",
    "# 1. Definir los modelos base (Base Learners)\n",
    "# Usamos configuraciones robustas para cada uno\n",
    "estimators = [\n",
    "    ('xgb', xgb.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,  # Más lento = más precisión\n",
    "        max_depth=6,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        objective='reg:squarederror',\n",
    "        # Ojo: StackingRegressor maneja el fit internamente, no usamos early_stopping aquí\n",
    "        # para simplificar la compatibilidad, pero compensamos con learning_rate bajo.\n",
    "    )),\n",
    "    ('lgb', lgb.LGBMRegressor(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        feature_fraction=0.7,\n",
    "        bagging_fraction=0.7,\n",
    "        bagging_freq=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )),\n",
    "    ('cat', CatBoostRegressor(\n",
    "        iterations=2000,\n",
    "        learning_rate=0.01,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=3,       # Regularización específica de CatBoost\n",
    "        verbose=0,           # Silencioso\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "# 2. Definir el Meta-Modelo (Final Estimator)\n",
    "# RidgeCV es una regresión lineal con regularización L2 integrada (Sección 7.13.1)\n",
    "# Es ideal para combinar predicciones porque maneja la colinealidad.\n",
    "meta_model = RidgeCV()\n",
    "\n",
    "# 3. Construir el Stacking Regressor\n",
    "# cv=5 asegura que las predicciones intermedias se generen con validación cruzada (Sección 9.8)\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=False # False = El meta-modelo solo ve las predicciones, no los datos originales\n",
    ")\n",
    "\n",
    "print(\"Entrenando Stacking Regressor (esto tardará un poco)...\")\n",
    "# Entrenamos en TODO el conjunto de entrenamiento disponible\n",
    "stacking_model.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"¡Entrenamiento completado!\")\n",
    "\n",
    "# --- EVALUACIÓN ---\n",
    "print(\"\\n--- EVALUACIÓN EN VALIDACIÓN ---\")\n",
    "val_preds = stacking_model.predict(X_val_ready)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "print(f\"RMSE Stacking (Train/Val split): {rmse_val:.2f}\")\n",
    "\n",
    "# --- GENERACIÓN DE SUBMISSION ---\n",
    "print(\"\\n--- GENERANDO SUBMISSION FINAL ---\")\n",
    "kaggle_preds = stacking_model.predict(test_kaggle_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Kaggle shape: (2000, 74)\n"
     ]
    }
   ],
   "source": [
    "kaggle_predictions = model.predict(test_kaggle_ready)\n",
    "kaggle_predictions_xgb = best_model.predict(test_kaggle_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your predictions in a `submission.csv` file for scoring on the [leaderboard](https://www.kaggle.com/competitions/u-tad-birth-weight-point-prediction-2025/leaderboard)\n",
    "To submit your notebook click on **Submit to competition** and then **Submit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T16:14:19.922232Z",
     "iopub.status.busy": "2025-10-06T16:14:19.921888Z",
     "iopub.status.idle": "2025-10-06T16:14:19.936268Z",
     "shell.execute_reply": "2025-10-06T16:14:19.935662Z",
     "shell.execute_reply.started": "2025-10-06T16:14:19.922198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# do not modify this code\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "submission[\"DBWT\"] = final_predictions\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DBWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000</td>\n",
       "      <td>3715.575522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001</td>\n",
       "      <td>3043.298072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7002</td>\n",
       "      <td>3468.537452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7003</td>\n",
       "      <td>3359.938730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7004</td>\n",
       "      <td>3219.856953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id         DBWT\n",
       "0  7000  3715.575522\n",
       "1  7001  3043.298072\n",
       "2  7002  3468.537452\n",
       "3  7003  3359.938730\n",
       "4  7004  3219.856953"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13892590,
     "sourceId": 116374,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
